{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_SEED = 43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "z:\\venvs\\ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEYqDqqrkZJj"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_size = (80,64)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(image_size), \n",
        "        transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A feladat megoldását 2 külön adathalmazzal is szeretnénk megtenni:\n",
        "* első és fontosabb a celeba dataset, amely celebek arcait tartalmazza előfeldolgozottan (cropped, aligned)\n",
        "* második a danbooru dataset, amely anime karakterek arcait tartalmazza\n",
        "* (opcionálisan egy kevert adathalmazt is szeretnénk tesztelni, hogy milyen eredményeket tudunk kapni)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Az adathalmazokat előre letöltöttük és kicsomagoltuk a tömörített fájlokat, majd így egy volume segítségével kerülnek a containerhez felcsatolásra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mivel képgenerálásról beszélünk, a tesztelési fázis nem teljesen jelent egyértelmű feladatot\n",
        "Ennek ellenére felkészülünk training, validation és test dataloaderekkel is, melyeknek bemenete a random 8:1:1 arányban felosztott adathalmaz. Kimenetük pedig egy batch_size-onként \"adagolt\" adathalmaz a modellünknek, image_size formájú 3 csatornás (RGB) Tensorokként"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import paths\n",
        "import os\n",
        "\n",
        "path_list = paths.celeba\n",
        "# path_list = paths.danbooru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = ImageFolder(root=path_list[\"data\"], transform=image_transforms)\n",
        "train_data, val_data, test_data = random_split(\n",
        "    data, [0.8, 0.1, 0.1], generator=generator\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for x, _ in train_dataloader:\n",
        "#     print(x[0].shape)\n",
        "#     plt.imshow(x[0].permute(1, 2, 0))\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9U-k4qTkpWn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "from train import Trainer\n",
        "import paths\n",
        "\n",
        "# wandb.login()\n",
        "\n",
        "# wandb.init(project=\"dl-hf\")\n",
        "trainer = Trainer(parallel=False)\n",
        "trainer.add_paths(path_list)\n",
        "trainer.add_dataloaders(train_dataloader, val_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk6SsNLRkrEe"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2HqCbYKktRL"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.sample(model_path=os.path.join(path_list[\"model\"], \"model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = path_list[\"data\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1583/1583 [06:33<00:00,  4.02it/s]\n",
            "100%|██████████| 1583/1583 [05:59<00:00,  4.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3272947790833882\n"
          ]
        }
      ],
      "source": [
        "#TODO: paths\n",
        "trainer.test_FID(os.path.join(base_path, \"0\", \"_\"), os.path.join(base_path, \"1\", \"_\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
