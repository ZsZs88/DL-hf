{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_SEED = 43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "import wandb\n",
        "from train import Trainer\n",
        "import paths\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEYqDqqrkZJj"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_image_size = (80,64)\n",
        "danbooru_image_size = (64,64)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_image_transforms = transforms.Compose(\n",
        "    [transforms.Resize(celeba_image_size), transforms.ToTensor()]\n",
        ")\n",
        "\n",
        "danbooru_image_transforms = transforms.Compose(\n",
        "    [transforms.Resize(danbooru_image_size), transforms.ToTensor()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A feladat megoldását 2 külön adathalmazzal is szeretnénk megtenni:\n",
        "* első és fontosabb a danbooru dataset, amely celebek arcait tartalmazza előfeldolgozottan (cropped, aligned)\n",
        "* második a danbooru dataset, amely anime karakterek arcait tartalmazza\n",
        "* (opcionálisan egy kevert adathalmazt is szeretnénk tesztelni, hogy milyen eredményeket tudunk kapni)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Az adathalmazokat előre letöltöttük és kicsomagoltuk a tömörített fájlokat, majd így egy volume segítségével kerülnek a containerhez felcsatolásra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mivel képgenerálásról beszélünk, a tesztelési fázis nem teljesen jelent egyértelmű feladatot\n",
        "Ennek ellenére felkészülünk training, validation és test dataloaderekkel is, melyeknek bemenete a random 8:1:1 arányban felosztott adathalmaz. Kimenetük pedig egy batch_size-onként \"adagolt\" adathalmaz a modellünknek, image_size formájú 3 csatornás (RGB) Tensorokként"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
        "danbooru_generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def move_random_files(source_dir, dest_dir, num_or_percentage):\n",
        "    # Get the list of files in the source directory\n",
        "    files = os.listdir(source_dir)\n",
        "\n",
        "    if isinstance(num_or_percentage, float) and 0 <= num_or_percentage <= 1:\n",
        "        num_files_to_move = int(len(files) * num_or_percentage)\n",
        "    else:\n",
        "        num_files_to_move = int(num_or_percentage)\n",
        "\n",
        "    # Randomly select files to move\n",
        "    files_to_move = random.sample(files, num_files_to_move)\n",
        "\n",
        "    # Move selected files to the destination directory\n",
        "    for file in files_to_move:\n",
        "        source_path = os.path.join(source_dir, file)\n",
        "        dest_path = os.path.join(dest_dir, file)\n",
        "        shutil.move(source_path, dest_path)\n",
        "        print(f\"Moved {file} to {dest_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_directory = os.path.join(paths.celeba[\"data\"], \"0\")\n",
        "destination_directory = paths.celeba[\"test\"]\n",
        "\n",
        "move_random_files(source_directory, destination_directory, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_directory = os.path.join(paths.danbooru[\"data\"], \"0\")\n",
        "destination_directory = paths.danbooru[\"test\"]\n",
        "\n",
        "move_random_files(source_directory, destination_directory, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_data = ImageFolder(root=paths.celeba[\"data\"], transform=celeba_image_transforms)\n",
        "celeba_train_data, celeba_val_data = random_split(\n",
        "    celeba_data, [0.8, 0.2], generator=celeba_generator\n",
        ")\n",
        "\n",
        "celeba_train_dataloader = DataLoader(\n",
        "    celeba_train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        ")\n",
        "celeba_val_dataloader = DataLoader(\n",
        "    celeba_val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "danbooru_data = ImageFolder(root=paths.danbooru[\"data\"], transform=danbooru_image_transforms)\n",
        "danbooru_train_data, danbooru_val_data = random_split(\n",
        "    danbooru_data, [0.8, 0.2], generator=danbooru_generator\n",
        ")\n",
        "\n",
        "danbooru_train_dataloader = DataLoader(\n",
        "    danbooru_train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        ")\n",
        "danbooru_val_dataloader = DataLoader(\n",
        "    danbooru_val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9U-k4qTkpWn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.init(project=\"dl-hf_celeba\")\n",
        "celeba_trainer = Trainer(parallel=False)\n",
        "celeba_trainer.add_paths(paths.celeba)\n",
        "celeba_trainer.add_dataloaders(\n",
        "    celeba_train_dataloader, celeba_val_dataloader\n",
        ")\n",
        "celeba_trainer.modify_imagesize(celeba_image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.init(project=\"dl-hf_danbooru\")\n",
        "danbooru_trainer = Trainer(parallel=False)\n",
        "danbooru_trainer.add_paths(paths.danbooru)\n",
        "danbooru_trainer.add_dataloaders(\n",
        "    danbooru_train_dataloader, danbooru_val_dataloader\n",
        ")\n",
        "danbooru_trainer.modify_imagesize(danbooru_image_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk6SsNLRkrEe"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "danbooru_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2HqCbYKktRL"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize(image_size, path):\n",
        "    items = os.listdir(path)\n",
        "    for item in items:\n",
        "        filename = os.path.join(path, item)\n",
        "        if os.path.isfile(filename):\n",
        "            im = Image.open(filename)\n",
        "            # f, _ = os.path.splitext(filename)\n",
        "            # print(f)\n",
        "            imResize = im.resize(image_size, Image.ANTIALIAS)\n",
        "            imResize.save(filename, \"JPEG\", quality=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_trainer.add_model(os.path.join(paths.celeba[\"models\"], \"sample_35.pth\"))\n",
        "celeba_trainer.sample_without_figs(n_samples=512, batching=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resize(celeba_image_size, paths.celeba[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "celeba_trainer.test_FID(\n",
        "    paths.celeba[\"samples\"], paths.celeba[\"test\"], batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "danbooru_trainer.add_model(os.path.join(paths.danbooru[\"models\"], \"sample_30.pth\"))\n",
        "danbooru_trainer.sample_without_figs(n_samples = 512, batching=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resize(danbooru_image_size, paths.danbooru[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "danbooru_trainer.test_FID(\n",
        "    paths.danbooru[\"samples\"], paths.danbooru[\"test\"], batch_size=16\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
