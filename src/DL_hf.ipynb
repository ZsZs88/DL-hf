{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_SEED = 43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEYqDqqrkZJj"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_size = (64, 64)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(image_size), \n",
        "        transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A feladat megoldását 2 külön adathalmazzal is szeretnénk megtenni:\n",
        "* első és fontosabb a celeba dataset, amely celebek arcait tartalmazza előfeldolgozottan (cropped, aligned)\n",
        "* második a danbooru dataset, amely anime karakterek arcait tartalmazza\n",
        "* (opcionálisan egy kevert adathalmazt is szeretnénk tesztelni, hogy milyen eredményeket tudunk kapni)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Az adathalmazokat előre letöltöttük és kicsomagoltuk a tömörített fájlokat, majd így egy volume segítségével kerülnek a containerhez felcsatolásra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mivel képgenerálásról beszélünk, a tesztelési fázis nem teljesen jelent egyértelmű feladatot\n",
        "Ennek ellenére felkészülünk training, validation és test dataloaderekkel is, melyeknek bemenete a random 8:1:1 arányban felosztott adathalmaz. Kimenetük pedig egy batch_size-onként \"adagolt\" adathalmaz a modellünknek, image_size formájú 3 csatornás (RGB) Tensorokként"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import paths\n",
        "import os \n",
        "\n",
        "celeba = paths.celeba\n",
        "# danbooru = paths.danbooru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = ImageFolder(root=celeba[\"data\"], transform=image_transforms)\n",
        "train_data, val_data, test_data = random_split(data, [0.8, 0.1, 0.1], generator=generator)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for x, _ in train_dataloader:\n",
        "#     print(x[0].shape)\n",
        "#     plt.imshow(x[0].permute(1, 2, 0))\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9U-k4qTkpWn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "from train import Trainer\n",
        "import paths\n",
        "# wandb.login()\n",
        "\n",
        "# wandb.init(project=\"dl-hf\")\n",
        "trainer = Trainer()\n",
        "trainer.add_paths(paths.celeba)\n",
        "# trainer.add_dataloaders(train_dataloader, val_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk6SsNLRkrEe"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2HqCbYKktRL"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.sample(model_path=os.path.join(paths.celeba[\"model\"], 'model.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PLUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in z:\\venvs\\ai\\lib\\site-packages (from pytorch-fid) (1.24.1)\n",
            "Requirement already satisfied: pillow in z:\\venvs\\ai\\lib\\site-packages (from pytorch-fid) (9.3.0)\n",
            "Requirement already satisfied: scipy in z:\\venvs\\ai\\lib\\site-packages (from pytorch-fid) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in z:\\venvs\\ai\\lib\\site-packages (from pytorch-fid) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in z:\\venvs\\ai\\lib\\site-packages (from pytorch-fid) (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in z:\\venvs\\ai\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in z:\\venvs\\ai\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (4.4.0)\n",
            "Requirement already satisfied: sympy in z:\\venvs\\ai\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (1.12)\n",
            "Requirement already satisfied: networkx in z:\\venvs\\ai\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (3.0)\n",
            "Requirement already satisfied: jinja2 in z:\\venvs\\ai\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (3.1.2)\n",
            "Requirement already satisfied: fsspec in z:\\venvs\\ai\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (2023.10.0)\n",
            "Requirement already satisfied: requests in z:\\venvs\\ai\\lib\\site-packages (from torchvision>=0.2.2->pytorch-fid) (2.28.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in z:\\venvs\\ai\\lib\\site-packages (from jinja2->torch>=1.0.1->pytorch-fid) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in z:\\venvs\\ai\\lib\\site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in z:\\venvs\\ai\\lib\\site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in z:\\venvs\\ai\\lib\\site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in z:\\venvs\\ai\\lib\\site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in z:\\venvs\\ai\\lib\\site-packages (from sympy->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pytorch-fid"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
